{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re, string, unicodedata\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from textblob import TextBlob\n",
    "\n",
    "#import contractions\n",
    "#import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_words = set([\"asesinato\", \"asesino\", \"asesina\", \"matar\", \"mata\", \"mato\", \"apuñalar\",\"apuñalo\",\"pega\",\"pego\",\"apalizo\",\"golpea\",\"golpeo\",\"agredio\",\"agrede\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matar', 'apuñalar', 'agredio', 'golpea', 'asesino', 'pega', 'pego', 'mata', 'apuñalo', 'apalizo', 'golpeo', 'asesina', 'agrede', 'asesinato', 'mato'}\n"
     ]
    }
   ],
   "source": [
    "print(violence_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sean', 'tenidas', 'hemos', 'habré', 'habido', 'fuisteis', 'tendríais', 'no', 'fueses', 'otras', 'vuestra', 'estén', 'estarías', 'tenemos', 'sentid', 'tuyos', 'nuestra', 'ellas', 'tiene', 'del', 'todos', 'poco', 'estuviera', 'con', 'hayamos', 'habríais', 'esta', 'estad', 'ha', 'sintiendo', 'habéis', 'esto', 'desde', 'su', 'esos', 'estar', 'os', 'mío', 'nuestros', 'estuvisteis', 'soy', 'fueseis', 'tengo', 'una', 'será', 'tienen', 'habíamos', 'tenía', 'mis', 'tenéis', 'fuera', 'de', 'habíais', 'hubo', 'tendrán', 'serían', 'tuvieran', 'estuviésemos', 'estaremos', 'tuvieses', 'estamos', 'sentidos', 'porque', 'tenían', 'han', 'seré', 'otros', 'y', 'hubiéramos', 'seas', 'sí', 'tened', 'tuvimos', 'nuestras', 'algunas', 'el', 'la', 'estaríais', 'ellos', 'estaríamos', 'hubimos', 'estemos', 'tuvisteis', 'estuviste', 'seamos', 'eran', 'tengáis', 'vuestras', 'míos', 'tuvo', 'estuviesen', 'me', 'hubieran', 'fuéramos', 'haya', 'tendría', 'fuesen', 'uno', 'fuésemos', 'has', 'hayáis', 'tuvierais', 'tenidos', 'te', 'quien', 'habrías', 'tengas', 'teníamos', 'están', 'habréis', 'como', 'fueras', 'sentido', 'estuve', 'esa', 'hubierais', 'son', 'tuviesen', 'estarán', 'sería', 'tuyo', 'era', 'serías', 'se', 'hubiste', 'sus', 'entre', 'habidos', 'cuando', 'tuviésemos', 'estuviéramos', 'seríais', 'he', 'hubieseis', 'hayan', 'eso', 'estarás', 'estaba', 'fui', 'tuviste', 'cual', 'a', 'eres', 'estábamos', 'sentidas', 'habremos', 'más', 'estuvieses', 'por', 'estuvierais', 'tendrás', 'las', 'tendrá', 'algo', 'sea', 'habríamos', 'estás', 'hubiésemos', 'tengan', 'estaría', 'hubiese', 'vosostras', 'le', 'estarían', 'seréis', 'tuvieron', 'hasta', 'sobre', 'suya', 'vosostros', 'sin', 'tenías', 'hube', 'estoy', 'unos', 'estas', 'muchos', 'ti', 'hubieron', 'mí', 'antes', 'yo', 'tú', 'habrán', 'está', 'habrían', 'es', 'tendremos', 'tengamos', 'mías', 'los', 'estáis', 'hubisteis', 'estaban', 'él', 'tuyas', 'estuvo', 'tienes', 'durante', 'estaré', 'suyo', 'seremos', 'ya', 'estabas', 'esas', 'hubiera', 'serás', 'estés', 'fuiste', 'habida', 'erais', 'tenido', 'un', 'tendríamos', 'estado', 'tenga', 'donde', 'ante', 'habrá', 'hubiesen', 'eras', 'habían', 'siente', 'habría', 'tendrían', 'suyos', 'fuimos', 'otra', 'estando', 'mucho', 'estuvieron', 'nada', 'también', 'mi', 'suyas', 'tenida', 'este', 'estará', 'seáis', 'fue', 'estabais', 'fuerais', 'otro', 'nosotras', 'contra', 'somos', 'todo', 'muy', 'tu', 'seríamos', 'había', 'algunos', 'tuviese', 'habrás', 'tuvieseis', 'tuviera', 'tuya', 'habidas', 'esté', 'vuestros', 'sentida', 'fueran', 'nos', 'en', 'estos', 'mía', 'tendréis', 'teniendo', 'e', 'nuestro', 'sois', 'hay', 'al', 'ella', 'tus', 'tendrías', 'tuviéramos', 'tuve', 'tuvieras', 'estaréis', 'estadas', 'teníais', 'les', 'ni', 'éramos', 'estuvieseis', 'fuese', 'tanto', 'estada', 'tendré', 'estuviese', 'qué', 'lo', 'nosotros', 'quienes', 'estéis', 'o', 'hubieses', 'que', 'hubieras', 'hayas', 'serán', 'para', 'habías', 'estuvieras', 'estuvieran', 'vuestro', 'estuvimos', 'estados', 'ese', 'fueron', 'pero', 'habiendo'}\n"
     ]
    }
   ],
   "source": [
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MADRID_URL = \"https://www.madridiario.es/sucesos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\") #parser para que no se queje\n",
    "    return soup\n",
    "\n",
    "soup = get_soup(MADRID_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headers</th>\n",
       "      <th>datePublication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La piscina de Peñuelas, cerrada durante toda l...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rescatan el cuerpo sin vida de una madrileña e...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Más de 200 efectivos de la UME y Bomberos trab...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detenido en Barcelona un hombre sospechoso de ...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Más de 1.300 hectáreas calcinadas en Madrid po...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Una anciana, intoxicada al incendiarse su casa...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apuñalamiento mortal en un parque de Valdezarza</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Herida grave al volcar su coche en Los Santos ...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Un joven en silla de ruedas cae a las vías en ...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Desalojado un edificio por un incendio que dej...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Anticorrupción pide 7 años de cárcel para Calv...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              headers datePublication\n",
       "0   La piscina de Peñuelas, cerrada durante toda l...      2019-06-29\n",
       "1   Rescatan el cuerpo sin vida de una madrileña e...      2019-06-29\n",
       "2   Más de 200 efectivos de la UME y Bomberos trab...      2019-06-29\n",
       "3   Detenido en Barcelona un hombre sospechoso de ...      2019-06-29\n",
       "4   Más de 1.300 hectáreas calcinadas en Madrid po...      2019-06-29\n",
       "5   Una anciana, intoxicada al incendiarse su casa...      2019-06-28\n",
       "6     Apuñalamiento mortal en un parque de Valdezarza      2019-06-28\n",
       "7   Herida grave al volcar su coche en Los Santos ...      2019-06-28\n",
       "8   Un joven en silla de ruedas cae a las vías en ...      2019-06-28\n",
       "9   Desalojado un edificio por un incendio que dej...      2019-06-28\n",
       "10  Anticorrupción pide 7 años de cárcel para Calv...      2019-06-28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get headers and its publication date\n",
    "def get_headers(soup):\n",
    "    headers = []\n",
    "    date = []\n",
    "    \n",
    "    container = soup.find_all('div',{'class','n1 fueraNoticia'})\n",
    "    for item in container:\n",
    "        headers.append(item.find('h2',{'class','titulo'}).text)\n",
    "        date.append(item.find('meta',itemprop='datePublished').get('content')[:10])\n",
    "\n",
    "    if len(headers) == len(date):\n",
    "        return pd.DataFrame({\"headers\": headers, \"datePublication\": date})\n",
    "    else:\n",
    "        return -1 #exit with error because there is news with date\n",
    "\n",
    "        \n",
    "dfnews_raw = get_headers(soup)\n",
    "dfnews_raw.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nI will try to do all in just one function called clean\\n\\nfor i in range(0,len(df['tweet'])):\\n\\t\\t\\t# get rid of anythin that isnt a letter\\n\\n\\t\\t\\texclusion_list = ['[^a-zA-Z]','rt', 'http', 'co', 'RT']\\n\\t\\t\\texclusions = '|'.join(exclusion_list)\\n\\t\\t\\ttext = re.sub(exclusions, ' ' , df['tweet'][i])\\n\\t\\t\\ttext = text.lower()\\n\\t\\t\\twords = text.split()\\n\\t\\t\\twords = [word for word in words if not word in stopword_list]\\n\\t\\t\\t # only use stem of word\\n\\t\\t\\t#words = [ps.stem(word) for word in words]\\n\\t\\t\\tdf['clean_tweets'][i] = ' '.join(words)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "I will try to do all in just one function called clean\n",
    "\n",
    "for i in range(0,len(df['tweet'])):\n",
    "\t\t\t# get rid of anythin that isnt a letter\n",
    "\n",
    "\t\t\texclusion_list = ['[^a-zA-Z]','rt', 'http', 'co', 'RT']\n",
    "\t\t\texclusions = '|'.join(exclusion_list)\n",
    "\t\t\ttext = re.sub(exclusions, ' ' , df['tweet'][i])\n",
    "\t\t\ttext = text.lower()\n",
    "\t\t\twords = text.split()\n",
    "\t\t\twords = [word for word in words if not word in stopword_list]\n",
    "\t\t\t # only use stem of word\n",
    "\t\t\t#words = [ps.stem(word) for word in words]\n",
    "\t\t\tdf['clean_tweets'][i] = ' '.join(words)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headers</th>\n",
       "      <th>datePublication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la piscina de peñuelas, cerrada durante toda l...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rescatan el cuerpo sin vida de una madrileña e...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>más de 200 efectivos de la ume y bomberos trab...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detenido en barcelona un hombre sospechoso de ...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>más de 1.300 hectáreas calcinadas en madrid po...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>una anciana, intoxicada al incendiarse su casa...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headers datePublication\n",
       "0  la piscina de peñuelas, cerrada durante toda l...      2019-06-29\n",
       "1  rescatan el cuerpo sin vida de una madrileña e...      2019-06-29\n",
       "2  más de 200 efectivos de la ume y bomberos trab...      2019-06-29\n",
       "3  detenido en barcelona un hombre sospechoso de ...      2019-06-29\n",
       "4  más de 1.300 hectáreas calcinadas en madrid po...      2019-06-29\n",
       "5  una anciana, intoxicada al incendiarse su casa...      2019-06-28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of lower-cases\n",
    "def tolower (s):\n",
    "    return s.lower()\n",
    "\n",
    "\n",
    "dfnews_raw.headers = dfnews_raw.headers.apply(tolower)\n",
    "dfnews_raw.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headers</th>\n",
       "      <th>datePublication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la piscina de peñuelas, cerrada durante toda l...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rescatan el cuerpo sin vida de una madrileña e...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mas de 200 efectivos de la ume y bomberos trab...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detenido en barcelona un hombre sospechoso de ...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mas de 1.300 hectareas calcinadas en madrid po...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>una anciana, intoxicada al incendiarse su casa...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headers datePublication\n",
       "0  la piscina de peñuelas, cerrada durante toda l...      2019-06-29\n",
       "1  rescatan el cuerpo sin vida de una madrileña e...      2019-06-29\n",
       "2  mas de 200 efectivos de la ume y bomberos trab...      2019-06-29\n",
       "3  detenido en barcelona un hombre sospechoso de ...      2019-06-29\n",
       "4  mas de 1.300 hectareas calcinadas en madrid po...      2019-06-29\n",
       "5  una anciana, intoxicada al incendiarse su casa...      2019-06-28"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of accents\n",
    "def clean_accent(s):\n",
    "    return s.replace('á','a').replace('é','e').replace('í','i').replace('ó','o').replace('ú','u')\n",
    "\n",
    "dfnews_raw.headers = dfnews_raw.headers.apply(clean_accent)\n",
    "dfnews_raw.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to pass severals parameters without functools and operator\n",
    "#dfnews_raw.headers = dfnews_raw.headers.apply(clean_any_character(work_list,','))\n",
    "#dfnews_raw.headers = dfnews_raw.headers.apply(clean_charac, character=',')\n",
    "#dfnews_raw.headers = dfnews_raw.headers.apply(clean_charac, arg=(dfnews_raw,',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headers</th>\n",
       "      <th>datePublication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la piscina de peñuelas cerrada durante toda la...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rescatan el cuerpo sin vida de una madrileña e...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mas de 200 efectivos de la ume y bomberos trab...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detenido en barcelona un hombre sospechoso de ...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mas de 1.300 hectareas calcinadas en madrid po...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>una anciana intoxicada al incendiarse su casa ...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apuñalamiento mortal en un parque de valdezarza</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>herida grave al volcar su coche en los santos ...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>un joven en silla de ruedas cae a las vias en ...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>desalojado un edificio por un incendio que dej...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>anticorrupcion pide 7 años de carcel para calv...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              headers datePublication\n",
       "0   la piscina de peñuelas cerrada durante toda la...      2019-06-29\n",
       "1   rescatan el cuerpo sin vida de una madrileña e...      2019-06-29\n",
       "2   mas de 200 efectivos de la ume y bomberos trab...      2019-06-29\n",
       "3   detenido en barcelona un hombre sospechoso de ...      2019-06-29\n",
       "4   mas de 1.300 hectareas calcinadas en madrid po...      2019-06-29\n",
       "5   una anciana intoxicada al incendiarse su casa ...      2019-06-28\n",
       "6     apuñalamiento mortal en un parque de valdezarza      2019-06-28\n",
       "7   herida grave al volcar su coche en los santos ...      2019-06-28\n",
       "8   un joven en silla de ruedas cae a las vias en ...      2019-06-28\n",
       "9   desalojado un edificio por un incendio que dej...      2019-06-28\n",
       "10  anticorrupcion pide 7 años de carcel para calv...      2019-06-28"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get rid of commas\n",
    "def clean_commas(s):\n",
    "    return s.replace(',','')\n",
    "\n",
    "dfnews_raw.headers = dfnews_raw.headers.apply(clean_commas)\n",
    "dfnews_raw.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headers</th>\n",
       "      <th>datePublication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la piscina de peñuelas cerrada durante toda la...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rescatan el cuerpo sin vida de una madrileña e...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mas de 200 efectivos de la ume y bomberos trab...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detenido en barcelona un hombre sospechoso de ...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mas de 1.300 hectareas calcinadas en madrid po...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>una anciana intoxicada al incendiarse su casa ...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apuñalamiento mortal en un parque de valdezarza</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>herida grave al volcar su coche en los santos ...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>un joven en silla de ruedas cae a las vias en ...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>desalojado un edificio por un incendio que dej...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>anticorrupcion pide 7 años de carcel para calv...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>desarticulada una red de venta de cocaina en m...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>agresion a un empleado cuando cambiaba la cerr...</td>\n",
       "      <td>2019-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>muere un mecanico al caerle un coche encima en...</td>\n",
       "      <td>2019-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vuelca con un coche robado en su huida de la g...</td>\n",
       "      <td>2019-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>un incendio destruye una nave industrial en hu...</td>\n",
       "      <td>2019-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>un niño de 8 años grave tras un ahogamiento en...</td>\n",
       "      <td>2019-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>una anciana critica al quedar atrapada en su c...</td>\n",
       "      <td>2019-06-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              headers datePublication\n",
       "0   la piscina de peñuelas cerrada durante toda la...      2019-06-29\n",
       "1   rescatan el cuerpo sin vida de una madrileña e...      2019-06-29\n",
       "2   mas de 200 efectivos de la ume y bomberos trab...      2019-06-29\n",
       "3   detenido en barcelona un hombre sospechoso de ...      2019-06-29\n",
       "4   mas de 1.300 hectareas calcinadas en madrid po...      2019-06-29\n",
       "5   una anciana intoxicada al incendiarse su casa ...      2019-06-28\n",
       "6     apuñalamiento mortal en un parque de valdezarza      2019-06-28\n",
       "7   herida grave al volcar su coche en los santos ...      2019-06-28\n",
       "8   un joven en silla de ruedas cae a las vias en ...      2019-06-28\n",
       "9   desalojado un edificio por un incendio que dej...      2019-06-28\n",
       "10  anticorrupcion pide 7 años de carcel para calv...      2019-06-28\n",
       "11  desarticulada una red de venta de cocaina en m...      2019-06-28\n",
       "12  agresion a un empleado cuando cambiaba la cerr...      2019-06-27\n",
       "13  muere un mecanico al caerle un coche encima en...      2019-06-27\n",
       "14  vuelca con un coche robado en su huida de la g...      2019-06-27\n",
       "15  un incendio destruye una nave industrial en hu...      2019-06-27\n",
       "16  un niño de 8 años grave tras un ahogamiento en...      2019-06-26\n",
       "17  una anciana critica al quedar atrapada en su c...      2019-06-26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get rid of quotes\n",
    "def clean_quotes(s):\n",
    "    return s.replace('\\\"','').replace('\\'','')\n",
    "\n",
    "dfnews_raw.headers = dfnews_raw.headers.apply(clean_quotes)\n",
    "\n",
    "dfnews_clean_string = dfnews_raw.copy() #copy for sentiment study\n",
    "dfnews_clean_token = dfnews_raw.copy() #copy for word frequency study\n",
    "dfnews_clean_string.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headers</th>\n",
       "      <th>datePublication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[la, piscina, de, peñuelas, cerrada, durante, ...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[rescatan, el, cuerpo, sin, vida, de, una, mad...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mas, de, 200, efectivos, de, la, ume, y, bomb...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[detenido, en, barcelona, un, hombre, sospecho...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mas, de, 1.300, hectareas, calcinadas, en, ma...</td>\n",
       "      <td>2019-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[una, anciana, intoxicada, al, incendiarse, su...</td>\n",
       "      <td>2019-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headers datePublication\n",
       "0  [la, piscina, de, peñuelas, cerrada, durante, ...      2019-06-29\n",
       "1  [rescatan, el, cuerpo, sin, vida, de, una, mad...      2019-06-29\n",
       "2  [mas, de, 200, efectivos, de, la, ume, y, bomb...      2019-06-29\n",
       "3  [detenido, en, barcelona, un, hombre, sospecho...      2019-06-29\n",
       "4  [mas, de, 1.300, hectareas, calcinadas, en, ma...      2019-06-29\n",
       "5  [una, anciana, intoxicada, al, incendiarse, su...      2019-06-28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get each word / Tokenizar\n",
    "def token(s):\n",
    "    return nltk.word_tokenize(s)\n",
    "\n",
    "dfnews_clean_token.headers = dfnews_clean_string.headers.apply(token)\n",
    "dfnews_clean_token.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_news' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-912a7249bc32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcleaned_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_news\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token_news' is not defined"
     ]
    }
   ],
   "source": [
    "def clean_stopwords(lst):\n",
    "    \n",
    "    [row.remove(item) for row in list_tokens for item in row if item in stp_words]\n",
    "    return list_tokens\n",
    "    \n",
    "cleaned_data = clean_stopwords(token_news, stopWords)\n",
    "pprint(cleaned_data[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new = new + \" enfado\"\n",
    "new = [' '.join(item) for item in cleaned_data]\n",
    "\n",
    "\n",
    "for item in new:\n",
    "    if TextBlob(item).detect_language() == 'es':\n",
    "        print(\"1\")\n",
    "        analysis = TextBlob(str(item))\n",
    "        item = analysis.translate(to='spanish')\n",
    "        print(item)\n",
    "    analysis = TextBlob(str(item))\n",
    "    print(analysis.sentiment,\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "new = ' '.join(cleaned_data[1])\n",
    "print(new)\n",
    "print(TextBlob(new).detect_language())\n",
    "analysis = TextBlob(str(new))\n",
    "print(analysis.sentiment,\"\\n\")\n",
    "\n",
    "\n",
    "new = ' '.join(cleaned_data[2])\n",
    "print(new)\n",
    "print(TextBlob(new).detect_language())\n",
    "analysis = TextBlob(str(new))\n",
    "print(analysis.sentiment,\"\\n\")\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "new2 = analysis.translate(to='spanish')\n",
    "analysis = TextBlob(str(new2))\n",
    "print(analysis.sentiment)\n",
    "print(analysis.tags)\n",
    "#print(analysis.translate(to='spanish'))\n",
    "print(dir(analysis))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_item(list_tokens):\n",
    "    for index, row in enumerate(list_tokens):\n",
    "        list_tokens.insert(index+1, [])\n",
    "        list_tokens.insert(index+1, [])\n",
    "    return list_tokens\n",
    " \n",
    "print(new_item(cleaned_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violence_at_row(list_tokens,set_list):\n",
    "    for row in list_tokens:\n",
    "        for word in row:\n",
    "            if word in violence_words:\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in cleaned_data:\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
